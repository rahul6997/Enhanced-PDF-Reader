<!DOCTYPE HTML>
<html>
    <head>
        <title>Enhanced eBook Readability with Gaze Tracking</title>
        <script src="https://api.gazerecorder.com/GazeCloudAPI.js"></script>
        <style>
            body {
                overflow: hidden;
                margin: 0;
                font-family: Arial, sans-serif;
            }
            #content {
                height: 90vh;
                overflow-y: scroll;
                padding: 20px;
                box-sizing: border-box;
            }
            .highlight {
                background-color: yellow;
            }
        </style>
        <script type="text/javascript">
            var lastScrollY = 0;
            var highlightedElement = null;

            function handleGazeData(GazeData) {
                if (GazeData.state === 0) { // Only proceed if we have valid gaze data
                    let docX = GazeData.docX;
                    let docY = GazeData.docY;

                    // Automatic scrolling
                    autoScroll(docY);

                    // Highlight text where gaze is detected
                    highlightText(docX, docY);
                }
            }

            function autoScroll(docY) {
                const content = document.getElementById('content');
                const threshold = window.innerHeight * 0.1;
                const bottomThreshold = window.innerHeight - threshold;

                if (docY < threshold && lastScrollY > 0) {
                    content.scrollTop -= 5; // Scroll up
                } else if (docY > bottomThreshold && lastScrollY < content.scrollHeight) {
                    content.scrollTop += 5; // Scroll down
                }

                lastScrollY = content.scrollTop;
            }

            function highlightText(docX, docY) {
                if (highlightedElement) {
                    highlightedElement.classList.remove('highlight');
                }
                const element = document.elementFromPoint(docX, docY);
                if (element) {
                    element.classList.add('highlight');
                    highlightedElement = element;
                }
            }

            window.addEventListener("load", function() {
                GazeCloudAPI.OnCalibrationComplete = function() { console.log('Gaze Calibration Complete'); }
                GazeCloudAPI.OnCamDenied = function() { console.log('Camera access denied'); }
                GazeCloudAPI.OnError = function(msg) { console.log('Error: ' + msg); }
                GazeCloudAPI.UseClickRecalibration = false;
                GazeCloudAPI.OnResult = handleGazeData;
            });
        </script>
    </head>
    <body>
        <h1>Enhanced eBook Readability</h1>
        <button type="button" onclick="GazeCloudAPI.StartEyeTracking();">Start Eye Tracking</button>
        <button type="button" onclick="GazeCloudAPI.StopEyeTracking();">Stop Eye Tracking</button>
        <div id="content">
            <h1>Peek A Boo: Enhancing Readability with Eye and Head Tracking</h1>
            <h3>1. Research Question</h3>
            <p>How can we improve the readability of e-books and PDFs, and what additional advancements in technology can be leveraged to further improve the reading experience?</p>
            <h3>2. Abstract</h3>
            <p>This HCI Research Project introduces a cutting-edge application designed to enhance e-book and PDF readability using eye and head-tracking technologies. It features automatic scrolling, smart navigation, interactive highlighting, and adaptive readability settings for a personalized and comfortable reading experience. The application also includes a focus mode, health-oriented reminders, blinking-based annotations, and personalized insights and recommendations based on reading habits, aiming to create a more intuitive and engaging interaction with digital content. While research in the field of HCI is limited, no one has specifically addressed the improvement of readability for digital reading.</p>
            <h3>3. Motivation</h3>
            <p>The main motivation behind this project is because of my personal struggles with reading on devices like Kindles and iPads at night. The user interfaces seemed outdated to me, lacking in features that could make reading more comfortable and safer for the eyes. Inspired to change this, I envisioned an app that combines modern, user-friendly design with features aimed at reducing eye strain, such as reminders to take breaks and to blink more frequently—a practice recommended by doctors for eye health. My own experience of worsening eyesight due to extensive reading, coupled with the need to wear glasses, motivated me to develop a solution that enhances the reading experience. I wanted to create an application that not only makes digital reading easier and more enjoyable but also prioritizes the health of the reader’s eyes. This app is designed to be a helpful companion for anyone who loves to read, particularly those who rely on glasses, making digital reading a pleasurable experience while prioritizing eye health.</p>
            <h3>4. Literature Review</h3>
            <h4>4.1 Eye/Head Tracking Technology to Improve HCI with iPad Applications</h4>
            <p>This paper focuses on leveraging eye/head tracking technology to enhance Human-Computer Interaction (HCI) with iPad applications, particularly for users with special needs. Their study introduces a system that uses the iPad’s front camera in conjunction with sophisticated eye and head tracking algorithms to enable control over applications without the need for direct physical interaction. This paper also discusses the implementation of OpenCV libraries for real-time facial feature detection, highlighting the efficiency and accuracy of the Haar Cascade algorithm for face detection under varying conditions. This technology was tested with a diverse group of 22 participants, demonstrating varying degrees of success (60 percent accuracy across different tests) in eye and pupil detection, influenced by factors such as lighting conditions and the presence of eyeglasses. The paper underscores the potential of eye/head tracking technologies in making digital interfaces more accessible to people with disabilities, offering a promising direction for future HCI research and development.</p>
            <h4>4.2 MobiET: A New Approach to Eye Tracking for Mobile Devices</h4>
            <p>This paper addresses the challenges of eye tracking on mobile devices due to hardware limitations that result in low-resolution images and, consequently, poor tracking accuracy. The authors, Anjie Zhu et al., introduce MobiET, a method that improves gaze fixation tracking on mobile devices. This technique involves extracting the rectangular area around the eye, identifying the geometric center (EC) and the iris center of gravity (IC), and then creating a vector from EC to IC. Through calibration, MobiET establishes a relationship between this vector and the screen’s gaze fixation coordinates. Evaluation of the approach showed promising results, achieving high accuracy within 2.34 to 4.69 degrees of visual angle for distances between the eyes and smartphone screen ranging from 22 to 28 centimeters, suggesting a significant advancement in mobile eye tracking technology.</p>
            <h4>4.3 Eye movement based human computer interaction</h4>
            <p>This paper explores the potential of eye movement as a novel input method for human computer interaction (HCI). It highlights the increasing need for quicker, non-intrusive ways to interact with the growing number of computing devices, proposing eye movement tracking as an efficient solution. The authors review various eye tracking techniques and algorithms that accurately determine the user’s gaze direction. The primary goal is to introduce new applications leveraging eye gaze technology to enhance the standard user’s reading experience, aiming to make digital reading more enjoyable. This work points toward the future of HCI, emphasizing eye tracking’s role in creating more accessible and user-friendly computing environments. This paper attempts to keep the user engaged by providing vivid font colors but fails to address the main issue of discomfort experienced by other users.</p>
            <h3>5. Proposed Methodology</h3>
            <p>In my HCI Research Project, I am presenting an application specifically designed to improve the readability of e-books and PDFs through innovative eye and head-tracking technologies. This application aims to create a more natural and engaging reading environment by adapting to the reader’s behavior and preferences in real-time.</p>
            <h4>5.1 Scrolling and Navigation:</h4>
            <p>My application will use advanced algorithms for smooth, automatic scrolling and smart page navigation, responding to where the reader looks and how they move their head, making manual swiping unnecessary.</p>
            <h4>5.2 Interactive Highlighting:</h4>
            <p>By implementing eye tracking, the app will automatically highlight key phrases or sentences that hold the reader’s attention longer, and use blink detection for highlighting text or pulling up definitions, enhancing understanding without breaking the flow of reading.</p>
            <h4>5.3 Adaptive Readability:</h4>
            <p>An adaptive interface will adjust text size and spacing based on the reader’s distance from the screen and signs of eye strain, ensuring optimal visibility and reducing eye strain for a comfortable reading experience.</p>
            <h4>5.4 Concentration Helper:</h4>
            <p>The app will feature a Focused Reading Mode that dims surrounding text, spotlighting the section under the reader’s gaze to help maintain focus and reduce distractions.</p>
            <h4>5.5 Health Considerations:</h4>
            <p>To support reading wellness, the app will track reading duration and intensity, offering timely reminders to rest the eyes. It will also adjust the screen’s brightness and contrast according to ambient light and reading focus, fostering a comfortable reading setting.</p>
            <h4>5.6 Enhanced Interaction:</h4>
            <p>Blinking-based annotations will allow readers to highlight text or take notes effortlessly by focusing on specific words or phrases, simplifying the process of marking important information.</p>
            <h4>5.7 Personalized Insights:</h4>
            <p>Lastly, the application will not only provide personalized insights and recommendations based on reading speed and gaze patterns to enhance reading efficiency and comprehension but will also recommend relevant books based on the user’s reading habits. This feature aims to personalize the reading experience further, matching it with individual preferences and habits for a truly customized engagement with content.</p>
            <h3>6. Sprint 2: Deliverable</h3>
            <h4>6.1 Sprint 2 Highlights:</h4>
            <p>This brief update outlines the key advancements in my project proposal, highlighting our practical implementation of eye-tracking technology. Without delving into technical specifics, our focus has been on creating a user-friendly interface that responds dynamically to eye and head movements. By integrating GazeCloudAPI, we’ve enhanced our application’s ability to make e-books and PDFs more interactive and reader-friendly.</p>
            <h4>6.2 Methodology</h4>
            <p>By leveraging GazeCloudAPI to track users’ eye movements and gaze patterns. This approach allows us to understand how readers interact with digital texts, enabling us to optimize content layout, adjust scrolling speeds, and improve overall readability based on individual preferences and behaviors.</p>
            <h4>6.3 Study Design</h4>
            <p>The study design focuses on assessing the effectiveness of eye-tracking technology in enhancing the reading experience. We plan to conduct a series of user tests, collecting qualitative and quantitative data on reading comfort, speed, and comprehension. This will involve participants from diverse demographics to ensure the applicability of our findings across a broad audience.</p>
            <h4>6.4 Implementation</h4>
            <p>In the implementation phase, we have more details on how GazeCloudAPI has been integrated into the application. This integration marks a pivotal step towards leveraging real-time online eye tracking to improve the user reading experience.</p>
            <h5>6.4.1 GazeCloudAPI Overview</h5>
            <p>GazeCloudAPI offers a seamless solution for implementing eye-tracking capabilities in web applications. It utilizes the device’s camera to track where the user is looking on the screen, enabling a range of interactive features such as automatic scrolling, gaze-activated controls, and analytics on reading patterns.</p>
            <h5>6.4.2 Integration steps</h5>
            <p>We’ve set up a simple example demonstrating the GazeCloudAPI’s integration, showcasing how real-time eye tracking can revolutionize the reading experience. This integration involved registering our domain to ensure secure API access, embedding the GazeCloudAPI JavaScript into our web application, and initiating eye tracking to dynamically respond to users’ gaze and engagement. We’ve set up callbacks to process gaze data in real-time and incorporated features to stop tracking for user privacy, calibrate gaze accurately, handle camera access permissions, and manage potential errors. These advancements not only mark progress in making digital reading more intuitive and accessible but also highlight our commitment to user-centered design and privacy.</p>
            <h3>7. Future Work</h3>
            <p>The goal is to implement automatic scrolling and navigation that syncs with the reader’s gaze and head movements, offering an effortless reading experience. This feature will adapt to each user’s individual pace and style, eliminating the need for manual interaction. Moreover, the application is set to enhance reader engagement with interactive highlighting that will spotlight text based on the duration and intensity of the reader’s focus, thereby enriching understanding without interrupting the flow. Looking ahead, the project will develop an adaptive interface that customizes text size, spacing, and layout in real-time to maximize readability and comfort, thereby reducing the potential for eye strain. The integration of GazeCloudAPI will also introduce a method for users to annotate text through simple eye movements, redefining the traditional process of note-taking. These future developments represent significant strides towards creating a digital reading environment that is both responsive and health-conscious, providing a personalized experience that aligns with natural human interactions. Next feature will detect the reader’s gaze direction and head movements, adjusting the scroll speed and page changes accordingly. This intuitive interaction eliminates the need for manual swiping, offering a seamless reading journey that adapts to the user’s natural reading pace and style.</p>
            <h3>References</h3>
            <p>[1] Ramsha Fatima, Atiya Usmani, and Zainab Zaheer. Eye movement based human computer interaction. In 2016 3rd International Conference on Recent Advances in Information Technology (RAIT), pages 489–494, 2016.</p>
            <p>[2] Asier Lopez-Basterretxea, Amaia Mendez-Zorrilla, and Begona Garcia-Zapirain. Eye/head tracking technology to improve hci with ipad applications. Sensors, 15(2):2244–2264, 2015.</p>
            <p>[3] Anjie Zhu, Qianjing Wei, Yilin Hu, Zhangwei Zhang, and Shiwei Cheng. MobiET: A new approach to eye tracking for mobile device. In 2018 ACM International Joint Conference and 2018 International Symposium, pages 862–869, 2018.</p>
        </div>
    </body>
</html>
